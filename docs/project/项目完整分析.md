# Agent 智能体项目案例 — 完整分析

本文对当前项目做整体分析，包括定位、目录结构、核心模块、数据流、配置与运行方式，便于新人上手或二次开发。

---

## 1. 项目定位

本项目是一个**扫地机器人 / 扫拖一体机器人场景下的智能客服 Agent**，具备：

- **ReAct 推理**：思考 → 调用工具 → 观察结果 → 再思考，循环直到能回答用户；
- **多工具调用**：RAG 知识库检索、天气、用户位置/ID/月份、外部使用记录、报告上下文注入等；
- **RAG 总结**：向量检索 + LLM 总结，返回基于知识库的简洁答案；
- **报告场景**：支持「生成/查询个人使用报告」，通过固定流程（用户 ID → 月份 → fill_context_for_report → fetch_external_data）与动态提示词切换实现。

技术栈上以 **LangChain / LangGraph** 构建 Agent，**Chroma** 做向量存储，**通义（Tongyi）** 作云端对话模型，**Ollama** 作本地 Embedding（可选），配置与提示词均通过 YAML/文本文件管理。

---

## 2. 目录结构概览

```
项目根目录/
├── agent_app/                    # 主应用包
│   ├── agent/                    # Agent 核心与中间件
│   │   ├── react_agent.py         # ReAct Agent 封装、流式执行入口
│   │   ├── tools/
│   │   │   ├── agent_tools.py    # 所有 @tool 定义（RAG、天气、用户/月份、外部数据、报告上下文）
│   │   │   └── middleware.py     # 工具监控、模型调用前日志、报告场景提示词切换
│   ├── rag/                      # RAG 链路
│   │   ├── rag_service.py        # RAG 总结服务：检索 + 拼 prompt + LLM 总结
│   │   └── vector_store.py       # Chroma 向量库封装、文档加载与 MD5 去重
│   ├── model/
│   │   └── factory.py            # 模型工厂：聊天模型、DashScope/Ollama Embedding
│   └── utils/                    # 通用工具
│       ├── config_handler.py      # YAML 配置加载（rag/chroma/prompts/agent）
│       ├── path_tool.py           # 项目根路径、相对路径转绝对路径
│       ├── file_handler.py       # 文件 MD5、目录列举、PDF/TXT 转 Document
│       ├── prompt_loader.py       # 按配置加载 main/rag_summarize/report 提示词
│       └── logger_handler.py     # 日志（按日文件 + 控制台彩色）
├── config/                       # 配置文件（YAML）
│   ├── rag.yml                   # 对话/Embedding 模型名
│   ├── chroma.yml                # 向量库集合名、持久化路径、分块与检索参数、数据路径、MD5 存储
│   ├── prompts.yml               # 各提示词文件路径
│   └── agent.yml                 # 外部数据 CSV 路径
├── prompts/                      # 提示词正文
│   ├── main_prompt.txt            # Agent 系统提示词（角色、思考准则、工具说明、输出规则）
│   ├── rag_summarize.txt         # RAG 总结用模板（用户提问 + 参考资料 → 概括回答）
│   └── report_prompt.txt         # 报告场景专用提示词（动态切换）
├── data/                         # 业务数据
│   ├── *.txt                     # 知识库原文（扫地机器人问答、维护保养、选购指南等）
│   └── external/
│       └── records.csv           # 用户×月份维度的使用记录（报告数据源）
├── storage/                      # 运行时存储（建议 .gitignore）
│   ├── chroma_db/                # Chroma 向量库持久化
│   └── md5.text                  # 已入库文件 MD5，用于增量加载去重
├── logs/                         # 按日日志（建议 .gitignore）
├── docs/                         # 文档
│   ├── project/                  # 项目架构、本分析文档
│   └── python_study/             # Python 规范与学习笔记
└── test/                         # 测试
```

---

## 3. 核心模块说明

### 3.1 Agent 入口：`agent_app/agent/react_agent.py`

- **ReactAgent**：封装 `create_agent(model, system_prompt, tools, middleware)`，对外提供 `execute_stream(query)`。
- **流式输出**：`agent.stream(input_dict, stream_mode="values", context={"report": False})`，逐条取 `messages` 最后一条的 `content` 并 yield，供控制台或后续 Web 使用。
- **上下文 context**：初始 `report=False`；当工具 `fill_context_for_report` 被调用后，中间件将 `context["report"]` 置为 `True`，用于后续**动态提示词**切换为报告提示词。

### 3.2 工具层：`agent_app/agent/tools/agent_tools.py`

| 工具名 | 作用 | 入参 | 说明 |
|--------|------|------|------|
| `rag_summarize` | RAG 检索+总结 | `query` | 内部调用 RagSummarizeService，先向量检索再 LLM 总结 |
| `get_weather` | 天气（当前为 mock） | `city` | 返回固定格式的天气字符串 |
| `get_user_location` | 用户所在城市（mock） | 无 | 随机返回一个城市名 |
| `get_user_id` | 用户 ID（mock） | 无 | 随机返回一个用户 ID |
| `get_current_month` | 当前月份（mock） | 无 | 随机返回 YYYY-MM |
| `fetch_external_data` | 指定用户、月份的使用记录 | `user_id`, `month` | 从 `data/external/records.csv` 按 user_id、月份查一条，JSON 字符串返回；首次加载 CSV 后缓存 |
| `fill_context_for_report` | 报告场景上下文注入 | 无 | 无真实返回值，中间件据此将 `context["report"]=True`，后续模型用报告提示词 |

外部数据采用「user_id → month → 记录」的嵌套字典缓存，避免重复读 CSV。

### 3.3 中间件：`agent_app/agent/tools/middleware.py`

- **monitor_tool**（`@wrap_tool_call`）：每次工具调用前后打日志（工具名、入参、完成/失败）；若工具名为 `fill_context_for_report`，则设置 `runtime.context["report"] = True`。
- **log_before_model**（`@before_model`）：每次调用模型前打日志（当前消息条数、最后一条类型与内容摘要）。
- **report_prompt_switch**（`@dynamic_prompt`）：每次生成提示词前根据 `context["report"]` 决定返回系统提示词还是报告提示词，实现报告场景的提示词切换。

### 3.4 RAG 总结服务：`agent_app/rag/rag_service.py`

- **RagSummarizeService**：
  - 使用 **VectorStoreService** 的检索器按 `query` 取 top-k 文档；
  - 将「用户提问 + 参考资料」填入 **rag_summarize 提示词模板**（`prompts/rag_summarize.txt`），变量为 `{input}`、`{context}`；
  - 使用 **chat_model**（与 Agent 同一对话模型）生成总结，`StrOutputParser()` 得到最终字符串。
- 链式结构：`prompt_template | print_prompt | chat_model | StrOutputParser()`（`print_prompt` 为调试用，可移除）。
- **一次 rag_summarize 调用** = 一次**向量检索**（Embedding 模型 + Chroma）+ 一次**LLM 总结**（对话模型）。

### 3.5 向量存储服务：`agent_app/rag/vector_store.py`

- **VectorStoreService**：
  - **Chroma**：集合名、持久化目录、Embedding 函数来自配置与 model factory（当前为 `ollama_embedding_model`）；
  - **RecursiveCharacterTextSplitter**：chunk_size、chunk_overlap、separators 来自 `chroma.yml`。
- **load_document()**：
  - 扫描配置的 `data_path` 下允许类型（如 txt、pdf）；
  - 按文件 MD5 在 `storage/md5.text` 中去重，未出现过则加载（pdf_loader/txt_loader）→ 分块 → 写入 Chroma，并追加 MD5。
- **get_retriever()**：返回 as_retriever(search_kwargs={"k": chroma_config["k"]})，供 RAG 服务调用。

### 3.6 模型工厂：`agent_app/model/factory.py`

- **ChatModelFactory**：Tongyi 对话模型（`rag_config["chat_model_name"]`），供 Agent 与 RAG 总结使用。
- **EmbeddingModelFactory**：DashScope 文本 Embedding（`text-embedding-v1`），当前项目内 RAG 未用，可做扩展。
- **OllamaEmbeddingsModelFactory**：本地 Ollama Embedding（如 `qwen3-embedding:4b`），用于 Chroma 向量化与检索。
- 模块加载时即生成全局实例：`chat_model`、`embedding_model`、`ollama_embedding_model`，供各模块直接引用。

### 3.7 配置与提示词加载

- **config_handler**：根据 `path_tool` 得到的项目根路径，解析 `config/*.yml`，提供 `rag_config`、`chroma_config`、`prompts_config`、`agent_config`。
- **prompt_loader**：根据 `prompts_config` 中的路径键（如 `main_prompt_path`）读取 `prompts/*.txt`，提供 `load_system_prompt()`、`load_rag_summarize_prompt()`、`load_report_prompt()`。

---

## 4. 数据流与调用关系

### 4.1 用户一问的完整路径（以「我所在地区气温下如何保养」为例）

1. 用户输入：`扫地机器人在我所在的地区的气温下如何保养?`
2. **ReactAgent.execute_stream(query)** 将 query 放入 `messages`，调用 `agent.stream(..., context={"report": False})`。
3. **模型第 1 轮**：判断需要「用户所在城市」→ 调用 **get_user_location** → 得到如「南京市」；middleware 打工具日志。
4. **模型第 2 轮**：需要当地天气 → 调用 **get_weather(city="南京市")** → 得到「26℃、50% 湿度」等；middleware 打工具日志。
5. **模型第 3 轮**：需要保养知识 → 调用 **rag_summarize(query="扫地机器人在26摄氏度、50%湿度环境下的保养方法")**（此处 query 由模型根据用户问题+工具结果自行组织）：
   - **向量检索**：Embedding 将 query 向量化，Chroma 返回 top-k 文档；
   - **RAG 总结**：将 query + 参考资料填入 rag_summarize 模板，chat_model 生成概括回答字符串。
6. **模型第 4 轮**：工具结果已足够 → 整合成最终回复（日常清洁、防撞条、湿度管理、电池与耗材等），流式输出给用户。

整个过程中，**用户原始句未被系统替换**；传给 `rag_summarize` 的 `query` 是**模型在 ReAct 中根据用户意图与工具返回结果生成的检索用问题**。

### 4.2 报告场景流程（简要）

- 用户意图被识别为「生成/查询个人使用报告」。
- 系统提示词要求顺序：**get_user_id** → **get_current_month**（或用户指定月份）→ **fill_context_for_report** → **fetch_external_data**。
- **fill_context_for_report** 被调用后，middleware 将 `context["report"]` 设为 True，**report_prompt_switch** 之后返回报告提示词，模型在报告上下文中结合 `fetch_external_data` 的结果生成报告内容。

### 4.3 模块依赖关系（简化）

- **react_agent** 依赖：create_agent、agent_tools（所有 tool）、middleware、chat_model、prompt_loader（系统提示词）。
- **agent_tools** 依赖：RagSummarizeService、config（agent_config）、logger、path_tool；RAG 内部再依赖 vector_store、prompt_loader（rag_summarize）、chat_model。
- **vector_store** 依赖：Chroma、chroma_config、ollama_embedding_model、file_handler、path_tool、logger。
- **model/factory** 依赖：rag_config；被 agent、rag_service、vector_store 使用。

---

## 5. 配置文件说明

| 文件 | 主要键 | 含义 |
|------|--------|------|
| **config/rag.yml** | chat_model_name, embedding_model_name, local_embedding_model_name | 对话模型、云端/本地 Embedding 模型名 |
| **config/chroma.yml** | collection_name, persist_directory, k, data_path, md5_hex_store, allow_knowledge_file_type, chunk_size, chunk_overlap, separators | 向量库名、持久化路径、检索条数、知识库数据目录、MD5 文件、允许类型、分块参数 |
| **config/prompts.yml** | main_prompt_path, rag_summarize_prompt_path, report_prompt_path | 各提示词文件相对项目根的路径 |
| **config/agent.yml** | external_data_path | 用户使用记录 CSV 路径（如 data/external/records.csv） |

路径类配置在运行时由 **path_tool.get_abs_path()** 转为基于项目根目录的绝对路径；向量库与 MD5 文件落在 **storage/** 下，便于统一忽略版本控制。

---

## 6. 提示词角色

- **main_prompt.txt**：定义 Agent 身份（扫地机器人客服）、ReAct 思考准则、工具使用场景与约束、报告生成固定流程、输出规则。与 LangChain 传入的 `tools` 的 description 互补：description 提供「工具是什么」，提示词提供「何时用、按什么顺序用、禁止怎么用」。
- **rag_summarize.txt**：模板变量 `{input}`（用户提问/检索问题）、`{context}`（拼接好的参考资料），约束「仅基于参考资料概括、不编造、纯文本输出」。
- **report_prompt.txt**：报告场景下由 **report_prompt_switch** 动态注入，与系统提示词二选一，用于在「报告」上下文中生成个性化使用报告。

---

## 7. 运行与扩展

- **直接跑 Agent 流式对话**：  
  `python -m agent_app.agent.react_agent`（或运行 `react_agent.py` 的 `__main__`），默认会执行示例问题并流式打印到控制台。
- **构建/更新知识库**：  
  运行 `vector_store.py` 的 `__main__`：加载 `data/` 下配置的 txt/pdf，按 MD5 去重后写入 `storage/chroma_db`，并更新 `storage/md5.text`。
- **单独测 RAG 总结**：  
  运行 `rag_service.py` 的 `__main__`：对固定 query 做检索+总结并打印。

扩展方向示例：接入真实天气 API、将 get_user_id/get_current_month 与登录/会话绑定、增加 Streamlit/Web API 暴露 `execute_stream`、替换或增加 Embedding/对话模型（如多模态 Embedding）、在 middleware 中增加埋点或权限校验等。

---

## 8. 小结

本项目是一个**基于 ReAct + 多工具 + RAG + 动态提示词**的扫地机器人客服 Agent：用户提问经多轮「模型推理 → 工具调用（含 RAG 检索与总结）→ 观察 → 再推理」后得到回答；报告场景通过专用工具与中间件切换提示词实现。各模块职责清晰：agent 负责编排与流式输出，tools 负责能力暴露，rag 负责检索与总结，vector_store 负责向量化与持久化，config/prompt 负责配置与提示词管理。理解上述数据流与配置后，即可在此基础上做功能扩展或业务定制。
