# 向量库上传功能设计

## 1. 功能概述

用户通过 QQ 向机器人发送**特定指令 + 文字**或**特定指令 + 文件（.txt / .pdf）**，将内容解析后存入向量数据库（Chroma），供后续检索/问答使用。

设计参考思路：
- **指令解析与会话**：NoneBot 插件（类似 agent 智能体中的命令处理）
- **文档加载、分块、向量化与存储**：LangChain 文档加载器 + 文本分割 + Embedding + Chroma（类似 langchainstudy 中的 RAG 流程）

---

## 2. 用户交互方式

| 方式 | 示例 | 说明 |
|------|------|------|
| 指令 + 纯文本 | `@机器人 /存储 这是一段要保存的笔记内容` | 将引号内或整行文本存入向量库 |
| 指令 + 文件 | 先发 `/存储`，再在后续消息中发送一个 .txt 或 .pdf 附件 | 或将指令与文件同条消息发送（依适配器能力） |

**约定指令**（可配置）：
- 主指令：`/存储`、`/存入`、`/vector_add`
- 别名：`store`、`add_doc`（便于中英文混用）

---

## 3. 系统架构

```
用户消息 (QQ)
    ↓
NoneBot 插件 (解析指令 + 文本/文件)
    ↓
├─ 文本 → 直接进入流水线
└─ 文件 → 下载/取 URL → 按类型选 Loader (.txt / .pdf)
    ↓
LangChain 文档加载 (TextLoader / PyPDFLoader)
    ↓
文本分割 (RecursiveCharacterTextSplitter)
    ↓
Embedding 模型 (本地 SentenceTransformer 或 开放 API)
    ↓
Chroma 向量库 (持久化到 chroma_db/)
    ↓
回复用户：「已存入 N 个片段」
```

---

## 4. 模块划分

### 4.1 插件层：`src/plugins/vector_store.py`

- **职责**：识别「存储」指令、区分文本/文件、调用服务层。
- **关键逻辑**：
  - 使用 `on_command("存储", aliases=...)` 或 `on_message` + 规则匹配指令前缀。
  - **文本**：从 `CommandArg` 或 `got()` 的后续消息中取 `get_plaintext()`，若为空则提示「请发送要存储的文本或文件」。
  - **文件**：从 `event.get_message()` 中遍历 `MessageSegment`，识别 QQ 适配器中的附件（如 `data["url"]` 或 `file`），只接受 `.txt` / `.pdf`；下载到临时目录后交给「文档处理服务」。
- **依赖**：调用 `services/vector_store_service.py`（或项目内实际服务路径）的「添加文本/添加文件」接口。

### 4.2 服务层：文档处理与向量入库（可放在 `src/services/` 或插件同目录）

- **文档加载**：
  - `.txt`：LangChain `TextLoader`（或 `UnstructuredFileLoader`）。
  - `.pdf`：LangChain `PyPDFLoader`（需 `pypdf`）。
- **分块**：`RecursiveCharacterTextSplitter`（chunk_size / chunk_overlap 可配置）。
- **向量化**：  
  - 方案 A：本地 `SentenceTransformerEmbeddings`（如 `all-MiniLM-L6-v2`），无需外网。  
  - 方案 B：OpenAI/其他 API 的 Embedding（需配置 API Key）。
- **存储**：`langchain_chroma.Chroma.from_documents()`，`persist_directory` 指向 `./chroma_db`（与 `.gitignore` 中一致，避免提交）。

### 4.3 配置

- **环境变量**（示例）：
  - `CHROMA_PERSIST_DIR`：向量库持久化目录，默认 `./chroma_db`。
  - `EMBEDDING_MODEL`：本地模型名或 API 类型。
  - 若用 API：`OPENAI_API_KEY` 等。
- **可选**：在 `pyproject.toml` 或单独配置文件中增加 chunk_size、chunk_overlap、允许的文件扩展名等。

---

## 5. 数据流详述

### 5.1 指令 + 文本

1. 用户：`@机器人 /存储 今天学习了 LangChain 的 Chroma 用法`
2. 插件：匹配到 `/存储`，取 `CommandArg` 或整条消息的 `get_plaintext()`，去掉指令前缀得到「今天学习了 …」
3. 服务层：将这段文本视为一个「文档」，做分块 → Embedding → 写入 Chroma（可带 metadata，如 `source="inline"`, `user_id=xxx`）。
4. 回复：`已存入，共 N 个片段。`

### 5.2 指令 + 文件

1. 用户：发送 `/存储`，随后发一条带 .txt 或 .pdf 附件的消息（或同条消息内带附件，依 QQ 适配器能力）。
2. 插件：识别到附件（通过 MessageSegment 的 type 与 url/file 等），校验扩展名 → 下载到临时文件。
3. 服务层：  
   - `.txt` → `TextLoader(path).load()`  
   - `.pdf` → `PyPDFLoader(path).load()`  
   再统一分块、Embedding、`Chroma.add_documents()`（或 `from_documents` 追加）。
4. 清理临时文件；回复：`已从「文件名」存入，共 N 个片段。`

---

## 6. 依赖建议

在 `pyproject.toml` 的 `dependencies` 中增加（示例版本可按需调整）：

```toml
# 向量库与 LangChain
"langchain>=0.3.0",
"langchain-chroma>=0.1.0",
"langchain-community>=0.3.0",
"chromadb>=0.4.0",

# 文档加载
"pypdf>=4.0.0",

# 本地 Embedding（二选一或都装）
"sentence-transformers>=2.2.0",
# "openai>=1.0.0",   # 若用 OpenAI Embedding
```

---

## 7. 插件注册

- 插件放在 `src/plugins/` 下，例如 `vector_store.py`。
- 若使用 `plugin_dirs = ["src/plugins"]`，NoneBot 会自动加载；无需在 `pyproject.toml` 的 `[tool.nonebot.plugins]` 里写死，除非要显式启用/禁用。

---

## 8. 安全与限制

- **文件类型**：仅允许 `.txt`、`.pdf`，禁止可执行文件；下载后按扩展名分支，其余拒绝。
- **大小与长度**：可对单文件大小、单段文本长度做上限（如 10MB、50KB），避免滥用。
- **权限**：可仅允许特定 user_id / 群 使用「存储」指令（在插件内用 `event.get_user_id()` 等做校验）。
- **敏感信息**：向量库目录已在 `.gitignore`，不提交；API Key 仅放在环境变量或 `.env.prod` 等不提交文件中。

---

## 9. 后续扩展

- **命名空间/集合**：按群、用户或主题使用不同 Chroma collection，便于多租户。
- **检索指令**：新增如 `/检索 问题`，对同一向量库做 `similarity_search`，再交给 LLM 生成回复（RAG）。
- **删除/清空**：按 metadata 或 collection 提供「删除最近一次」或「清空我的存储」等指令。

---

## 10. 参考

- **NoneBot**：`on_command`、`CommandArg`、`event.get_plaintext()`、`Message`/`MessageSegment`（QQ 适配器文档）。
- **LangChain**：`TextLoader`、`PyPDFLoader`、`RecursiveCharacterTextSplitter`、`Chroma.from_documents()`、`SentenceTransformerEmbeddings`。
- 项目内：`src/plugins/weather.py`（命令解析）、`src/plugins/on_message_example.py`（消息与规则）。
